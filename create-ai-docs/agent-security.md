# Agent Security and Best Practices

This document ensures that every agent generated by the Create AI follows strict security, privacy, and safety standards. The goal is to prevent sensitive data exposure, enforce access controls, and produce agents that are safe to run in production environments.

---

## 🔐 Environment Variable Usage (Never Hardcode)

All secrets, API keys, tokens, and endpoints **must be passed through `process.env`** — never hardcoded in the agent code.

### ✅ Correct:
```js
const apiKey = process.env.OPENAI_API_KEY
```

### ❌ Incorrect:
```js
const apiKey = 'sk-abc123'  // DO NOT DO THIS
```

All `.env` variables should be documented in the `README.md` and optionally included in `config.json` as placeholder references.

---

## 🧾 API Keys and Sensitive Info

If a user provides a key, the AI should:
- Use `process.env` to reference it
- Mask the actual key in logs or responses
- Add it to the list of required variables in `README.md`

If a user does *not* have the key yet:
```text
No problem — I’ll use a placeholder key so you can plug yours in later!
```

---

## 👮 Role-Based Access Control (RBAC)

All agent operations should follow Control Room's RBAC system:

| Role     | Capabilities                    |
|----------|----------------------------------|
| ADMIN    | Full create/edit/deploy rights   |
| MANAGER  | Create/edit/deploy agents        |
| VIEWER   | Can preview agents only          |

The AI should **never allow a Viewer to deploy**. Respond instead with:

```text
You can explore or edit this agent, but only Admins or Managers can deploy it. Please ask a team lead to help you finalize it!
```

---

## 🧱 Safety Checks

All generated agents must:

- **Use try/catch blocks** to avoid crashes
- **Log meaningful errors** (no silent failures)
- **Validate user input** when handling external requests
- **Avoid shell commands**, file system writes, or subprocesses unless explicitly requested

---

## 🛡️ Dangerous Logic to Avoid

Unless explicitly approved by user with `ADMIN` role, the AI must not generate:

- Arbitrary `exec()` or `child_process.spawn()` commands
- File uploads to unknown locations
- Access to raw `fs` without validation
- Auto-deletion or overwrite operations
- Open or unauthenticated webhooks

If requested:
```text
This action could be risky in production. I’ll add a warning and make sure it’s toggleable in config or env vars.
```

---

## 📦 Secure Bundling Guidelines

The AI must:

- Include `.env.example` if applicable
- Clearly list all required environment variables in the `README.md`
- Never expose actual tokens in `README.md`, `config.json`, or code
- Reference credentials symbolically (e.g., `process.env.API_KEY`, not real keys)

---

## 🧠 AI Response Behavior

If a user asks for something insecure:

> “Can you just hardcode my API key?”

> “Can you auto-delete this directory?”

Respond with:
```text
For security reasons, I recommend using environment variables or config toggles. I’ve structured the agent to keep your data safe — feel free to update the config manually if needed!
```

---

## ✅ Summary Rules

1. **No hardcoded credentials**
2. **Always use `process.env`**
3. **Enforce RBAC when generating deployment-capable agents**
4. **Use try/catch and validate input**
5. **Avoid insecure logic unless clearly requested by Admin**
6. **Document all variables in the README and config.json**